# ðŸ”¬ Technical Details â€” Truth Chain

This document captures the **implementation details** of Truth Chain that are separated from the main README for clarity.  
It explains how claims are processed, how tools are orchestrated, and how evaluation is performed.  

---

## ðŸ›  Tool Integrations
Truth Chain uses modular tool wrappers located in the `Tools/` directory:

- **Google Search** â€” Serper API (`google_search.py`)  
- **PubMed** â€” NCBI E-utilities API (`pubmed_tool.py`)  
- **Arxiv** â€” Arxiv API + PyMuPDF (for summaries) (`arxiv_tool.py`)  
- **Wikipedia** â€” Python `wikipedia` library (`wikipedia_search.py`)  
- **Tavily** â€” Tavily Search API (`tavily_search.py`)  

ðŸ‘‰ Each tool retrieves raw evidence (snippets, abstracts, or full articles).  
ðŸ‘‰ Evidence is **summarized relative to the claim** using helper functions in `utils.py`.  

---

## ðŸ“„ Summarization Logic
- Located in `utils.py` (`summarize_article_with_focus`).  
- **Fetcher:** `trafilatura` â€” extracts the main content from article URLs.  
- **Process:**  
  1. Limit article size with a safeguard (`max_chars=4000`).  
  2. Pass the article + user claim into a focused LLM prompt.  
  3. Generate 2â€“3 paragraphs highlighting only content **relevant to the claim**.  

This ensures Truth Chain bases verdicts on **article-level context**, not just shallow snippets.  

---

## ðŸ¤– Router & Verdict Nodes
- **Router Node** (`LangGraph.py`)  
  - Implemented as `decide_tools_node`.  
  - Uses an LLM prompt to **categorize the claim** and return a Python list of relevant tools.  
  - Special handling for **Tavily** if the claim contains recency markers (*â€œtoday,â€ â€œlast week,â€ â€œrecentlyâ€*).  
  - Fallback: defaults to `['Google']` if classification fails.  

- **Verdict Node**  
  - Collects all **focused summaries** from the selected tools.  
  - LLM outputs a structured verdict:  
    - âœ… `True`  
    - âŒ `False`  
    - ðŸ¤· `Unverifiable`  
  - Includes a concise reasoning string alongside the verdict.  

---

## ðŸ— Orchestration
Truth Chain uses **LangGraph** to model the reasoning flow as a modular state graph:

1. **Router Node** â†’ decide relevant tools.  
2. **Tool Nodes** â†’ query APIs and fetch evidence.  
3. **Summarizers** â†’ condense evidence relative to the claim.  
4. **Verdict Node** â†’ aggregate summaries and produce the final verdict.  

This modular design makes it easy to add or swap tools without breaking the pipeline.  

---

## ðŸ“Š Evaluation
- **Script:** `evaluate.py`  
- **Dataset:** 32 claims with ground-truth labels.  
- **Models tested:**  
  - GPT-4o â†’ **87.5% (28/32 correct)**  
  - GPT-4o-mini â†’ **84.38% (27/32 correct)**  
- **Flow:**  
  1. Load claims from CSV (`claim,ground_truth`).  
  2. Route â†’ Tools â†’ Summaries â†’ Verdict.  
  3. Compare verdict with ground truth.  
  4. Log metrics to CSV and display results in the READMEâ€™s evaluation table.  

---

## ðŸ— Deployment
- Hosted live on **AWS EC2**.  
- Dependencies installed **globally** (not inside a virtual environment).  
- Run via `nohup` to keep the app alive after SSH logout:  
  ```bash
  nohup streamlit run Main.py --server.port 8502 --server.address 0.0.0.0 > truthchain.log 2>&1 &
