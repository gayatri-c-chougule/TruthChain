import requests
import os
import trafilatura
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

# === Load Environment Variables (e.g., API keys, secrets, configs) ===
load_dotenv()

# === Setup LLM (GPT-4o) ===
MODEL_NAME = os.getenv("OPENAI_MODEL", "gpt-4o")
MODEL_TEMP = float(os.getenv("OPENAI_TEMPERATURE", "0.0"))

llm = ChatOpenAI(model=MODEL_NAME, temperature=MODEL_TEMP)  # Configurable via .env


# === Article Extraction from URL ===
def get_article(link: str) -> str:
    """
    Fetch and extract the main article content from a given URL using Trafilatura.

    This function first tries to use `trafilatura.fetch_url()` for optimized extraction.
    If it fails, it falls back to a manual `requests` call + Trafilatura's HTML extractor.

    Args:
        link (str): The URL of the article to extract.

    Returns:
        str: Cleaned article text if successful, otherwise an error message.
    """
    try:
        # Try direct fetch (Trafilatura handles redirects, canonical links, etc.)
        downloaded = trafilatura.fetch_url(link)
        if downloaded:
            article_text = trafilatura.extract(downloaded)
            if article_text:
                return article_text.strip()

        # Fallback: Raw HTML + extract
        html = requests.get(link, timeout=10).text
        article_text = trafilatura.extract(html)
        if article_text:
            return article_text.strip()

        return "‚ùå Could not extract article text."

    except Exception as e:
        return f"‚ùå Error fetching article: {e}"


# === Prompt Template for Focused Summarization ===
FOCUSED_SUMMARY_PROMPT = PromptTemplate.from_template("""
You are a helpful assistant. Summarize the following article **specifically in relation to** this statement:

> "{focus}"

Your summary should only include the parts of the article that support, contradict, or are relevant to this statement.
Keep it to 2‚Äì3 focused paragraphs. Do not include information unrelated to the focus.

Article:
{text}
""")


# === Focused Summarization ===
def summarize_article_with_focus(text: str, focus: str, max_chars: int = 4000) -> str:
    """
    Use LLM to generate a focused summary of the article with respect to a user-defined statement.

    Args:
        text (str): The full article text (unstructured).
        focus (str): A claim or topic to filter and summarize the content by.
        max_chars (int): Truncate the article to this many characters (to fit prompt limits).

    Returns:
        str: A concise, focused summary generated by the LLM, or error message.
    """
    if not text or text.startswith("‚ùå"):
        return "‚ùå No article text to summarize."

    # Clip article to avoid prompt overflow
    text = text[:max_chars]

    # Format prompt with focus + text
    prompt = FOCUSED_SUMMARY_PROMPT.format(text=text, focus=focus)

    try:
        result = llm.invoke(prompt)
        return result.content.strip()

    except Exception as e:
        return f"‚ùå LLM summarization failed: {e}"


# === Manual Test Block (optional for module-level testing) ===
# if __name__ == "__main__":
#     url = "https://www.pewresearch.org/journalism/2024/10/10/americans-views-of-2024-election-news/"
#     claim = "Americans are losing trust in election-related news coverage."

#     print(f"üîó Fetching article from:\n{url}\n")
#     article_text = get_article(url)

#     if article_text.startswith("‚ùå"):
#         print(article_text)
#     else:
#         print(f"‚úÖ Article fetched (length: {len(article_text)} chars)")
#         print("\nü§ñ Summarizing with respect to claim:")
#         print(f"‚Üí {claim}\n")

#         summary = summarize_article_with_focus(article_text, focus=claim)
#         print("üßæ Focused Summary:\n")
#         print(summary)
